{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ðŸŽ“ **Professor**: Apostolos Filippas\n",
    "\n",
    "### ðŸ“˜ **Class**: AI Engineering\n",
    "\n",
    "### ðŸ“‹ **Topic**: You Can Just Build Things\n",
    "\n",
    "ðŸš« **Note**: You are not allowed to share the contents of this notebook with anyone outside this class without written permission by the professor.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome!\n",
    "\n",
    "In our firstfour lectures, we've covered how\n",
    "1. We can call LLMs via APIs and get structured responses\n",
    "2. We can build lexical search with BM25\n",
    "3. We can build semantic search with embeddings\n",
    "4. We can combine lexical and semantic search into hybrid search\n",
    "\n",
    "Today you will put it all together by building a Retrieval Augmented Generation (RAG) system.\n",
    "- This is a question-answering bot that can answer questions about Fordham University\n",
    "- You will use real data scraped from the Fordham website.\n",
    "\n",
    "\n",
    "Your RAG pipeline will look like this:\n",
    "\n",
    "```\n",
    "User Question\n",
    "     â†“\n",
    "1. RETRIEVE: Find relevant documents (search!)\n",
    "     â†“\n",
    "2. AUGMENT: Stuff those documents into a prompt\n",
    "     â†“\n",
    "3. GENERATE: Ask an LLM to answer using the context\n",
    "     â†“\n",
    "Answer\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1. Look at your data\n",
    "\n",
    "In `data/fordham-website.zip` you'll find **~9,500 Markdown files** scraped from Fordham's website. Each file is one page â€” admissions info, program descriptions, faculty pages, financial aid, campus life, and more.\n",
    "\n",
    "Your task: **look at the data**\n",
    "- The first step in any AI engineering or data science project should always be to familiarize yourself with the data.\n",
    "- I cannot stress this enough.. without this step, it's hard to build anything useful.\n",
    "\n",
    "Tips:\n",
    "- Unzip the archive and look at some of the files. \n",
    "- Open a few in a text editor. \n",
    "- Get a feel for what you're working with.\n",
    "- The first line of every file is always the **URL** of the page it was scraped from. The rest is the page content converted to Markdown. Here's an example â€” `gabelli-school-of-business_veterans.md`:\n",
    "\n",
    "```markdown\n",
    "https://www.fordham.edu/gabelli-school-of-business/veterans\n",
    "\n",
    "# Military Veterans & Active Duty Members of the Military\n",
    "\n",
    "## Transform Your Knowledge & Skills Into a Business Career for the Future\n",
    "\n",
    "As a veteran or an active duty member of the United States Armed Services,\n",
    "you have gained or are currently acquiring the invaluable organizational,\n",
    "leadership, analytics, and technical knowledge and skills that hiring\n",
    "managers seek. These transferrable skills provide a major advantage in\n",
    "emerging, business-related industries where innovation, a global mind-set,\n",
    "and the ability to lead individuals and teams in the continuously evolving\n",
    "work environment, are critical for success.\n",
    "\n",
    "By completing a graduate or undergraduate business degree at the Gabelli\n",
    "School of Business, you can prepare for a lifelong career in some of\n",
    "today's fastest-growing fields. ...\n",
    "\n",
    "### Study at a Top-Ranked, Military-Friendly University\n",
    "\n",
    "The Gabelli School of Business is part of Fordham University, the only\n",
    "New York City university to be among those ranked \"Best for Vets\" by\n",
    "Military Times. ...\n",
    "\n",
    "### Learn How the Yellow Ribbon Program Works\n",
    "\n",
    "The Yellow Ribbon GI Education Enhancement Program, or the Yellow Ribbon\n",
    "Program, is a part of the Post-9/11 Veterans Educational Assistance Act\n",
    "of 2008. ...\n",
    "```\n",
    "\n",
    "The filenames mirror the URL structure â€” underscores replace path separators (e.g. `gabelli-school-of-business_veterans.md` came from `/gabelli-school-of-business/veterans`). Some files are short (a few lines), others are quite long.\n",
    "\n",
    "- Once you've looked around, load the files into Python. Python's built-in `zipfile` module can read zip archives without extracting to disk. Load them into a list of dictionaries or a DataFrame with at least two fields: the filename (or a clean page name) and the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from directory: data/fordham-website\n",
      "Found 9530 markdown files.\n",
      "Loaded 9530 documents.\n",
      "                                            filename  \\\n",
      "0  about_living-the-mission_campus-ministry_catho...   \n",
      "1  academics_centers-and-institutes_center-for-et...   \n",
      "2  graduate-school-of-arts-and-sciences_student-r...   \n",
      "3  academics_departments_psychology_graduate-prog...   \n",
      "4  academics_departments_african--african-america...   \n",
      "\n",
      "                                                 url  \\\n",
      "0  https://www.fordham.edu/about/living-the-missi...   \n",
      "1  https://www.fordham.edu/academics/centers-and-...   \n",
      "2  https://www.fordham.edu/graduate-school-of-art...   \n",
      "3  https://www.fordham.edu/academics/departments/...   \n",
      "4  https://www.fordham.edu/academics/departments/...   \n",
      "\n",
      "                                             content  \n",
      "0  # Ministry of Music\\n\\n\\nFordham offers each s...  \n",
      "1  # Advanced Certificate in Health Care Ethics C...  \n",
      "2  Skip to Main Content\\nGraduate School of Arts ...  \n",
      "3  # Alumni Profiles for Ph.D. in Applied Develop...  \n",
      "4  # African and African American Studies Faculty...  \n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "def load_fordham_data(source_path):\n",
    "    data = []\n",
    "    \n",
    "    # 1. Check if it's a zip file\n",
    "    if source_path.endswith('.zip') and os.path.exists(source_path):\n",
    "        print(f\"Loading from zip: {source_path}\")\n",
    "        with zipfile.ZipFile(source_path, 'r') as z:\n",
    "            file_list = [f for f in z.namelist() if f.endswith('.md')]\n",
    "            for file_name in file_list:\n",
    "                with z.open(file_name) as f:\n",
    "                    try:\n",
    "                        content = f.read().decode('utf-8')\n",
    "                    except UnicodeDecodeError:\n",
    "                        continue\n",
    "                    \n",
    "                    lines = content.split('\\n', 1)\n",
    "                    url = lines[0].strip() if lines else \"\"\n",
    "                    body = lines[1].strip() if len(lines) > 1 else \"\"\n",
    "                    \n",
    "                    data.append({\n",
    "                        \"filename\": file_name,\n",
    "                        \"url\": url,\n",
    "                        \"content\": body\n",
    "                    })\n",
    "                    \n",
    "    # 2. Check if it's a directory (Robust Fallback)\n",
    "    elif os.path.exists(source_path) and os.path.isdir(source_path):\n",
    "        print(f\"Loading from directory: {source_path}\")\n",
    "        path = pathlib.Path(source_path)\n",
    "        files = list(path.glob('*.md'))\n",
    "        print(f\"Found {len(files)} markdown files.\")\n",
    "        \n",
    "        for file_path in files:\n",
    "             try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    lines = f.readlines()\n",
    "                    if not lines: continue\n",
    "                    \n",
    "                    url = lines[0].strip()\n",
    "                    content = \"\".join(lines[1:]).strip()\n",
    "                    \n",
    "                    data.append({\n",
    "                        \"filename\": file_path.name,\n",
    "                        \"url\": url,\n",
    "                        \"content\": content\n",
    "                    })\n",
    "             except Exception as e:\n",
    "                print(f\"Error reading {file_path}: {e}\")\n",
    "                \n",
    "    else:\n",
    "        print(f\"Source not found or invalid: {source_path}\")\n",
    "        # Try default locations if provided path fails\n",
    "        fallback_dir = 'data/fordham-website'\n",
    "        if source_path != fallback_dir and os.path.exists(fallback_dir) and os.path.isdir(fallback_dir):\n",
    "             print(f\"Fallback: Loading from {fallback_dir}\")\n",
    "             return load_fordham_data(fallback_dir) # Recursive call\n",
    "             \n",
    "        return pd.DataFrame()\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Usage - Point to the directory since you extracted it\n",
    "source_path = 'data/fordham-website' \n",
    "df = load_fordham_data(source_path)\n",
    "\n",
    "print(f\"Loaded {len(df)} documents.\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. Chunk the Documents\n",
    "\n",
    "Some of the pages could be too long to embed as a single unit. Down the line, the pages may be too long to stuff into the LLM's prompt during the generation step. As such, most of the RAG systems will break down big documents into into smaller **chunks**.\n",
    "\n",
    "> ðŸ“š **TERM: Chunking**  \n",
    "> Splitting documents into smaller, self-contained pieces for embedding and retrieval. The goal is chunks that are small enough to be specific, but large enough to be meaningful.\n",
    "\n",
    "Your task: **write a function that splits each document into chunks.**\n",
    "\n",
    "Things to think about:\n",
    "- What's a reasonable chunk size? (Think about what fits in a prompt vs. what's too vague)\n",
    "- Should you split on sentences? Paragraphs? A fixed character/word count?\n",
    "- Should chunks overlap? What happens if an answer spans two chunks?\n",
    "- How do you keep track of which document each chunk came from? You may need that information down the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 66082 chunks from 9530 documents.\n",
      "                                            chunk_id  \\\n",
      "0  about_living-the-mission_campus-ministry_catho...   \n",
      "1  about_living-the-mission_campus-ministry_catho...   \n",
      "2  about_living-the-mission_campus-ministry_catho...   \n",
      "3  about_living-the-mission_campus-ministry_catho...   \n",
      "4  about_living-the-mission_campus-ministry_catho...   \n",
      "\n",
      "                                          source_url  \\\n",
      "0  https://www.fordham.edu/about/living-the-missi...   \n",
      "1  https://www.fordham.edu/about/living-the-missi...   \n",
      "2  https://www.fordham.edu/about/living-the-missi...   \n",
      "3  https://www.fordham.edu/about/living-the-missi...   \n",
      "4  https://www.fordham.edu/about/living-the-missi...   \n",
      "\n",
      "                                             content  \\\n",
      "0  # Ministry of Music\\n\\n\\nFordham offers each s...   \n",
      "1  itan area over the live radio broadcast by WFU...   \n",
      "2  mble:**Liturgical/Worship - Mixed Voices**Memb...   \n",
      "3  ers at the 7:00 p.m. Sunday Mass in the Univer...   \n",
      "4  #### What type of music do we sing?\\n\\nWe sing...   \n",
      "\n",
      "                                         parent_file  \n",
      "0  about_living-the-mission_campus-ministry_catho...  \n",
      "1  about_living-the-mission_campus-ministry_catho...  \n",
      "2  about_living-the-mission_campus-ministry_catho...  \n",
      "3  about_living-the-mission_campus-ministry_catho...  \n",
      "4  about_living-the-mission_campus-ministry_catho...  \n"
     ]
    }
   ],
   "source": [
    "def chunk_text(text, chunk_size=800, overlap=150):\n",
    "    chunks = []\n",
    "    if not text:\n",
    "        return chunks\n",
    "        \n",
    "    start = 0\n",
    "    text_len = len(text)\n",
    "    \n",
    "    while start < text_len:\n",
    "        end = start + chunk_size\n",
    "        chunk = text[start:end]\n",
    "        chunks.append(chunk)\n",
    "        # Move the start pointer forward\n",
    "        step = chunk_size - overlap\n",
    "        if step <= 0: step = 1 # Avoid infinite loop\n",
    "        start += step\n",
    "        \n",
    "    return chunks\n",
    "\n",
    "def process_to_chunks(df):\n",
    "    chunked_data = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        # Get content, default to empty string if missing\n",
    "        content = row.get('content', '')\n",
    "        if not isinstance(content, str): content = \"\"\n",
    "            \n",
    "        # Split the body content into pieces\n",
    "        text_chunks = chunk_text(content)\n",
    "        \n",
    "        for i, chunk_content in enumerate(text_chunks):\n",
    "            # Only add non-empty chunks if you prefer\n",
    "            if not chunk_content.strip(): continue\n",
    "                \n",
    "            chunked_data.append({\n",
    "                \"chunk_id\": f\"{row['filename']}_{i}\",\n",
    "                \"source_url\": row['url'],\n",
    "                \"content\": chunk_content.strip(),\n",
    "                \"parent_file\": row['filename']\n",
    "            })\n",
    "            \n",
    "    return pd.DataFrame(chunked_data)\n",
    "\n",
    "# Apply the function to create df_chunks\n",
    "df_chunks = process_to_chunks(df)\n",
    "\n",
    "print(f\"Generated {len(df_chunks)} chunks from {len(df)} documents.\")\n",
    "print(df_chunks.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 66082 chunks from 9530 documents.\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "df_chunks = process_to_chunks(df)\n",
    "print(f\"Generated {len(df_chunks)} chunks from {len(df)} documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. Embed the Chunks\n",
    "\n",
    "Now we need to turn each chunk into a vector so we can search over them. You've done this before in Lecture 4.\n",
    "\n",
    "Your task: **embed all chunks using an embedding model.**\n",
    "\n",
    "Tips:\n",
    "- You could use a local model, or API model. What are the tradeoffs?\n",
    "- This will take a while if you do it serially. You might want to use async/batch.\n",
    "- Once you've created your embeddings, you may want to save them to disk so you don't have to redo this step every time\n",
    "- You'll need to embed queries with the **same model** at search time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c18898787e4716a2af54c38b871d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataframe size: 66082\n",
      "Sampled dataframe size: 6608\n",
      "Embedding 6608 chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b4e775c42b5488999d1129aa6076de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/207 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding complete.\n",
      "                                            chunk_id  \\\n",
      "0      info_24004_faculty_7156_steven_j_franks.md_14   \n",
      "1  information-technology_it-security--assurance_...   \n",
      "2  academics_departments_english_graduate_current...   \n",
      "3  about_leadership-and-administration_administra...   \n",
      "4  about_leadership-and-administration_administra...   \n",
      "\n",
      "                                          source_url  \\\n",
      "0  https://www.fordham.edu/info/24004/faculty/715...   \n",
      "1  https://www.fordham.edu/information-technology...   \n",
      "2  https://www.fordham.edu/academics/departments/...   \n",
      "3  https://www.fordham.edu/about/leadership-and-a...   \n",
      "4  https://www.fordham.edu/about/leadership-and-a...   \n",
      "\n",
      "                                             content  \\\n",
      "0  iming of flowering. American Journal of Botany...   \n",
      "1  e, or networked.\\n\\n## Policy Statement\\n\\n- T...   \n",
      "2  uage in which Beowulf was composed. Students w...   \n",
      "3  t ways to share the results, and propose short...   \n",
      "4  ernal guest for business-related meals (exclud...   \n",
      "\n",
      "                                         parent_file  \\\n",
      "0         info_24004_faculty_7156_steven_j_franks.md   \n",
      "1  information-technology_it-security--assurance_...   \n",
      "2  academics_departments_english_graduate_current...   \n",
      "3  about_leadership-and-administration_administra...   \n",
      "4  about_leadership-and-administration_administra...   \n",
      "\n",
      "                                           embedding  \n",
      "0  [-0.13366616, -0.026994644, -0.0043448624, 0.0...  \n",
      "1  [-0.06402686, 0.07485838, 0.01763079, -0.09304...  \n",
      "2  [0.033112384, 0.008940181, 0.046873268, -0.011...  \n",
      "3  [-0.03888547, -0.0961397, 0.09203895, -0.01515...  \n",
      "4  [0.03416291, 0.082438566, -0.0024262115, -0.05...  \n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# 1. Initialize the model\n",
    "# 'all-MiniLM-L6-v2' is a small, fast model great for local use\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# 2. Sample 10% of the data to speed up processing\n",
    "print(f\"Original dataframe size: {len(df_chunks)}\")\n",
    "# Use a fixed random state for reproducibility\n",
    "df_chunks = df_chunks.sample(frac=0.1, random_state=42).reset_index(drop=True)\n",
    "print(f\"Sampled dataframe size: {len(df_chunks)}\")\n",
    "\n",
    "# 3. Get the list of texts to embed\n",
    "# We use the 'content' column of our chunks dataframe\n",
    "chunk_texts = df_chunks['content'].tolist()\n",
    "\n",
    "print(f\"Embedding {len(chunk_texts)} chunks...\")\n",
    "\n",
    "# 4. Embed the chunks\n",
    "# The model handles batching automatically\n",
    "embeddings = model.encode(chunk_texts, show_progress_bar=True)\n",
    "\n",
    "# 5. Add embeddings to the dataframe \n",
    "df_chunks['embedding'] = list(embeddings)\n",
    "\n",
    "print(\"Embedding complete.\")\n",
    "print(df_chunks.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4. Retrieve\n",
    "\n",
    "Now build the **R** in RAG. Given a user's question, find the most relevant chunks.\n",
    "\n",
    "Your task: **write a retrieval function that takes a question and returns the most relevant chunks.**\n",
    "\n",
    "Tips:\n",
    "- You can use lexical or semantic search or both!\n",
    "- How many chunks should you retrieve? Too few and you might miss the answer; too many and you'll overwhelm the LLM (and pay more tokens)\n",
    "- Try a few test questions and eyeball whether the retrieved chunks are relevant\n",
    "- Try a few questions and see what comes back. For example:\n",
    "  - \"What programs does the Gabelli School of Business offer?\"\n",
    "  - \"How do I apply for financial aid?\"\n",
    "  - \"Where is Fordham's campus?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: What programs does the Gabelli School of Business offer?\n",
      "  - [undergraduate-admission_apply_how-to-apply_transfer-students_the-transfer-application-process.md] l-of-business/academic-programs-and-admissions/undergraduate-programs/which-campus/lincoln-center/)) and a corresponding major on their application. A...\n",
      "  - [undergraduate-admission_transfer-students.md] l-of-business/academic-programs-and-admissions/undergraduate-programs/which-campus/lincoln-center/)) and a corresponding major on their application. A...\n",
      "  - [gabelli-school-of-business_student-and-career-resources_undergraduate-student-resources_academic-advising_first-year-advising_information-for-new-students.md] the wisdom and experience of two assigned upperclass student mentorsâ€”your FAM. They will serve as invaluable resources and guides as you navigate your...\n",
      "  - [undergraduate-admission_majors-and-minors_accounting-information-systems.md] counting majors are offered through the Gabelli School of Business at Rose Hill. New York City is your living lab to explore the power of business, fr...\n",
      "  - [gabelli-school-of-business_academic-programs-and-admissions_undergraduate-programs_undergraduate-highlighted-courses.md] # Undergraduate Highlighted Courses\n",
      "\n",
      "## Fall 2024 Course Highlights\n",
      "\n",
      "\n",
      "The Gabelli School of Business offers a broad selection of undergraduate courses...\n",
      "\n",
      "Question: How do I apply for financial aid?\n",
      "  - [families_i-am-a-parent-of_prospective-students.md] e](/undergraduate-admission/apply/dates-and-deadlines/). -\n",
      "Thanks in part to many generous donors and alumni, 81 percent of undergraduate students rec...\n",
      "  - [graduate-school-of-education_admissions_information-for-admitted-students.md] , federal aid, and external funding.\n",
      "\n",
      "If you indicated that you are interested in GSE Financial Aid on your application, you will receive an email det...\n",
      "  - [student-financial-services_undergraduate-financial-aid_international-students.md] # Financial Aid Guidance for International Students\n",
      "\n",
      "At Fordham, we know that applying for financial aid as an international student comes with its ow...\n",
      "  - [graduate-school-of-arts-and-sciences_admissions_admissions-faq.md] ss interest in your Statement of Purpose. -\n",
      "All applicants admitted to GSAS Ph.D. programs receive full financial support packages with\n",
      "\n",
      "[Graduate Ass...\n",
      "  - [student-financial-services.md] ered for institutional aid (including early action applicants accepted during the regular decision process), you must file both the Free Application f...\n",
      "\n",
      "Question: Where is Fordham's campus?\n",
      "  - [about_campuses_westchester-campus_contact-us.md] Fordham School of Professional and Continuing Studies**Debbie Lesperance, Director of Admissions and Recruitment\n",
      "\n",
      "914-367-3302\n",
      "\n",
      "[[email protected]](/c...\n",
      "  - [info_21200_school_of_professional_and_continuing_studies.md] wers! Email us at [email protected] or call (718) 817-2600, or complete an inquiry form.](https://pcsadmissions.fordham.edu/register/pcsinfo)\n",
      "\n",
      "## Scho...\n",
      "  - [families_i-am-a-parent-of_transfer-students.md] gistration, academic course, financial aid, and bill payment information. It also contains bookmarks, a calendar, an online directory, campus announce...\n",
      "  - [families.md] a complete list of hours and locations, please visit [ fordham.campusdish.com](http://fordham.campusdish.com/). We can't wait for you to dine with us ...\n",
      "  - [about_mission-statement.md] sources shape and enhance Fordham's professional and undergraduate programs.\n",
      "\n",
      "Fordham is privileged to share a history and a destiny with New York Cit...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def retrieve(query, df, top_k=5):\n",
    "    # 1. Embed the query\n",
    "    query_embedding = model.encode([query])[0]\n",
    "    \n",
    "    # 2. Get embeddings from dataframe as a matrix\n",
    "    embeddings = np.stack(df['embedding'].values)\n",
    "    \n",
    "    # 3. Normalize for cosine similarity\n",
    "    query_norm = query_embedding / np.linalg.norm(query_embedding)\n",
    "    embeddings_norm = embeddings / np.linalg.norm(embeddings, axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # 4. Calculate similarity scores (Dot Product)\n",
    "    scores = np.dot(embeddings_norm, query_norm)\n",
    "    \n",
    "    # 5. Get top k indices\n",
    "    top_k_indices = np.argsort(scores)[::-1][:top_k]\n",
    "    \n",
    "    # 6. Return the top k rows\n",
    "    return df.iloc[top_k_indices]\n",
    "\n",
    "# Test it out!\n",
    "test_queries = [\n",
    "    \"What programs does the Gabelli School of Business offer?\",\n",
    "    \"How do I apply for financial aid?\",\n",
    "    \"Where is Fordham's campus?\"\n",
    "]\n",
    "\n",
    "for q in test_queries:\n",
    "    print(f\"\\nQuestion: {q}\")\n",
    "    results = retrieve(q, df_chunks)\n",
    "    \n",
    "    for i, row in results.iterrows():\n",
    "        # Handle different column names (filename vs parent_file)\n",
    "        filename = row.get('filename', row.get('parent_file', 'unknown_file'))\n",
    "        print(f\"  - [{filename}] {row['content'][:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5. Generate\n",
    "\n",
    "Now build the **G** in RAG. Take the retrieved chunks and pass them to an LLM along with the user's question.\n",
    "\n",
    "Your task: **write a function that takes a question and the retrieved chunks, builds a prompt, and calls an LLM to generate an answer.**\n",
    "\n",
    "Tips:\n",
    "- How should you structure the prompt? The LLM needs to know: (1) what is the context of the application, (2) what is the question, (3) what it should include in its answer\n",
    "- What should the LLM do if the context doesn't contain the answer?\n",
    "- Start with a cheap model; try a better one when you've figured out the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To apply for financial aid at Fordham University, you need to fill out both the Free Application for Federal Student Aid (FAFSA) to be considered for federal aid and the CSS Profile to be considered for institutional aid. Deadlines for these applications vary based on your choice of admission application (Early Action, Early Decision, or Regular Decision).\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# Ensure you have your API key set\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-...\" \n",
    "\n",
    "def generate_answer(query, df_chunks):\n",
    "    # 1. RETRIEVE: Get top k relevant chunks\n",
    "    # (Assuming you named your retrieval function 'retrieve' from Step 4)\n",
    "    relevant_docs = retrieve(query, df_chunks, top_k=5)\n",
    "    \n",
    "    # 2. AUGMENT: Format the chunks into a context string\n",
    "    context_list = []\n",
    "    for i, row in relevant_docs.iterrows():\n",
    "        # Handle filename/parent_file column naming issue safely\n",
    "        filename = row.get('filename', row.get('parent_file', 'unknown'))\n",
    "        context_list.append(f\"SOURCE: {filename}\\nCONTENT: {row['content']}\")\n",
    "    \n",
    "    context_block = \"\\n\\n---\\n\\n\".join(context_list)\n",
    "\n",
    "    # 3. PROMPT: Construct the final message\n",
    "    system_message = (\n",
    "        \"You are a helpful, professional assistant for Fordham University. \"\n",
    "        \"Answer the user's question ONLY using the provided context. \"\n",
    "        \"If the answer is not in the context, say 'I'm sorry, I don't have that information in the Fordham records.' \"\n",
    "        \"Do not use your own internal knowledge to make up facts.\"\n",
    "    )\n",
    "    \n",
    "    user_message = (\n",
    "        f\"Use the following Fordham University documents to answer the question:\\n\\n\"\n",
    "        f\"{context_block}\\n\\n\"\n",
    "        f\"Question: {query}\\n\"\n",
    "        f\"Answer:\"\n",
    "    )\n",
    "\n",
    "    # 4. GENERATE: Call the LLM (gpt-4o-mini is a great 'cheap' starting model)\n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error calling LLM: {e}\"\n",
    "\n",
    "# Usage\n",
    "answer = generate_answer(\"How do I apply for financial aid?\", df_chunks)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Testing RAG Generation with 5 questions ---\n",
      "\n",
      "Question 1: What specific programs does the Gabelli School of Business offer for undergraduates?\n",
      "------------------------------\n",
      "Answer:\n",
      "The Gabelli School of Business offers a broad selection of undergraduate programs that include a liberal arts core, a business core, a major and concentration, and electives. Specific majors are available, including accounting, and students can also choose from various minors and concentrations. More detailed information about the curriculum can be found in the course bulletin.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Question 2: Can you explain the difference between the Rose Hill and Lincoln Center campuses?\n",
      "------------------------------\n",
      "Answer:\n",
      "The Rose Hill campus features 85 acres with Gothic architecture and tree-lined walkways, while the Lincoln Center campus is an 8-acre site located in Manhattan at 60th Street and Columbus Avenue, spanning two city blocks with a landscaped plaza. The Rose Hill campus is known for its traditional campus environment, whereas the Lincoln Center campus offers a more urban experience.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Question 3: What are the application deadlines for early action vs regular decision?\n",
      "------------------------------\n",
      "Answer:\n",
      "I'm sorry, I don't have that information in the Fordham records.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Question 4: How does the yellow ribbon program work for veterans at Fordham?\n",
      "------------------------------\n",
      "Answer:\n",
      "The Yellow Ribbon Program at Fordham University allows degree-granting colleges and universities to voluntarily enter into an agreement with the Department of Veterans Affairs (VA) to fund tuition expenses that exceed the annual maximum cap per military academic year. Fordham guarantees full coverage of tuition and fees for eligible Post-9/11 GI BillÂ® veterans and their dependents through this program, with no cap, ensuring that cost is never a barrier to education for military-connected students.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Question 5: Who is the current president of Fordham University?\n",
      "------------------------------\n",
      "Answer:\n",
      "The current president of Fordham University is Tania Tetlow.\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of detailed questions to test the RAG system\n",
    "test_questions = [\n",
    "    \"What specific programs does the Gabelli School of Business offer for undergraduates?\",\n",
    "    \"Can you explain the difference between the Rose Hill and Lincoln Center campuses?\",\n",
    "    \"What are the application deadlines for early action vs regular decision?\",\n",
    "    \"How does the yellow ribbon program work for veterans at Fordham?\",\n",
    "    \"Who is the current president of Fordham University?\"\n",
    "]\n",
    "\n",
    "print(f\"--- Testing RAG Generation with {len(test_questions)} questions ---\\n\")\n",
    "\n",
    "for i, q in enumerate(test_questions):\n",
    "    print(f\"Question {i+1}: {q}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Generate the answer\n",
    "    # Make sure you have df_chunks available from Step 2\n",
    "    answer = generate_answer(q, df_chunks)\n",
    "    \n",
    "    print(f\"Answer:\\n{answer}\\n\")\n",
    "    print(\"=\" * 50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 6. Wire everything together\n",
    "\n",
    "Combine the previous steps into a simple function that takes in a question and returns an answer.\n",
    "\n",
    "Your task: **write a `rag(question)` function that retrieves relevant chunks and generates an answer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, I don't have that information in the Fordham records.\n"
     ]
    }
   ],
   "source": [
    "# Placeholder for your implementation\n",
    "def rag(question):\n",
    "    # This function is your main entry point\n",
    "    # It calls generate_answer, which in turn calls retrieve\n",
    "    return generate_answer(question, df_chunks)\n",
    "\n",
    "# Test the final system\n",
    "q = \"What is the tuition for the MBA program?\"\n",
    "print(rag(q))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 7. Evaluate, experiment and improve\n",
    "\n",
    "Your RAG system works â€” but there's always room to make it better. \n",
    "\n",
    "Your task: **evaluate, experiment, and improve your system**\n",
    "\n",
    "Tips:\n",
    "- How do you know that your system is working or that your changes are improving it?\n",
    "- Try different questions â€” where does it do well? Where does it struggle?\n",
    "- Adjust the number of retrieved chunks â€” what happens with more or fewer?\n",
    "- Try different chunking strategies â€” bigger chunks? Smaller? Overlap?\n",
    "- Try a different embedding model â€” does it change retrieval quality?\n",
    "- Improve the prompt â€” can you get better, more concise answers?\n",
    "- Add source attribution â€” can the system tell the user which pages the answer came from?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for your implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 8. (Optional) Make it an app\n",
    "\n",
    "So far your RAG system lives inside a notebook. That's great for development â€” but nobody is going to use your Jupyter notebook to ask questions about Fordham. Let's turn it into a real web app.\n",
    "\n",
    "> ðŸ“š **TERM: Streamlit**  \n",
    "> A Python library that turns plain Python scripts into interactive web apps. You write Python â€” no HTML, CSS, or JavaScript â€” and Streamlit renders it as a web page with inputs, buttons, and formatted output. It's the fastest way to go from \"I have a function\" to \"I have a web app.\"\n",
    "\n",
    "Your task: **create a Streamlit app that lets a user type a question about Fordham and get an answer from your RAG system.**\n",
    "\n",
    "To get started:\n",
    "- Install it: `uv pip install streamlit` \n",
    "- A Streamlit app is just a `.py` file (not a notebook). Create something like `fordham_rag_app.py`\n",
    "- Run it: `streamlit run scripts/fordham_rag_app.py` â€” this opens a browser tab with your app\n",
    "\n",
    "Tips:\n",
    "- Check out the [Streamlit docs](https://docs.streamlit.io/) â€” the \"Get started\" tutorial is very short\n",
    "- Your best bet is to vibecode your way to this. You'll be surprised how fast you can get it up and running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Summary\n",
    "\n",
    "## What You Built\n",
    "\n",
    "| Step | What You Did | What It Does |\n",
    "|------|-------------|-------------|\n",
    "| **Load** | Read 9,500+ Fordham web pages | Get raw content |\n",
    "| **Chunk** | Split pages into smaller pieces | Make content searchable and promptable |\n",
    "| **Embed** | Turn chunks into vectors | Enable semantic search |\n",
    "| **Retrieve** | Find relevant chunks for a question | The **R** in RAG |\n",
    "| **Generate** | Ask an LLM to answer using the chunks | The **G** in RAG |\n",
    "| **RAG** | Wire it all together | Question in, answer out |\n",
    "\n",
    "## The Big Picture\n",
    "\n",
    "RAG is one of the most common patterns in AI engineering today. What you built here is the same core architecture behind tools like ChatGPT with search, Perplexity, enterprise Q&A bots, and more. The details get more sophisticated (vector databases, reranking, query rewriting, evaluation) but the pattern is the same:\n",
    "\n",
    "**Find relevant stuff â†’ give it to an LLM â†’ get an answer.**\n",
    "\n",
    "You can just build things."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
