https://www.fordham.edu/academics/research/office-of-research/events/symposium-on-responsible-ai/participants/jie-ren-

# Jie Ren

**Bio:**

Dr. Jie Renâ€™s research on responsible AI primarily examines AI bias. Specifically, Dr. Ren has identified gender bias in how GenAI responds differently to different self-disclosed genders when individual users discuss mental health issues, as well as ownership-driven bias, where GenAI responses mirror the political leanings of the company that owns the model (ongoing project). In addition, Dr. Ren has written about the business consequences of AI bias in *CXOTech Magazine*.

**Abstract:**

We investigate the level of empathy mental health posts receive on social media and generative artificial intelligence (GenAI). Specifically, we examine gender effects to determine if posts authored by self-identified men, women, or unknown (no self-identified gender discloser) receive varying levels of empathy across different technical platforms. Using a sample of mental health posts from Reddit, we find that self-identified women receive more empathy relative to men across all platforms. We further find that Inflection Pi, a GenAI tool specifically designed to be empathetic, provides the most empathy, but it still favors self-identified women over men. Self-identified men attempting to receive empathy for their prolonged emotional distress are disadvantaged relative to self-identified women.