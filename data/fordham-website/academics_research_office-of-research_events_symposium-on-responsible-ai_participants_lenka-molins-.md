https://www.fordham.edu/academics/research/office-of-research/events/symposium-on-responsible-ai/participants/lenka-molins-

# Lenka Molins

**Bio:**

Lenka Molins serves as an Associate Director and risk advisor SME at Deloitte, where Molins advises leading technology companies on UK, EU, and US AI laws. Molins has conducted research on AI audit methodologies at the Oxford Internet Institute and completed a doctoral dissertation at Oxford focused on AI audit methodologies and AI laws, including the EU AI Act, NIST, ISO 42001, Canadian DADM, the U.S. Executive Order, NYC Local Law 144, and Colorado SB 21-169.

**Abstract:**

As artificial intelligence increasingly shapes decisions in credit scoring, predictive policing, medical diagnostics, and advertising, international organizations have called for the enforcement of AI audits across jurisdictions as a central mechanism of accountability. Several regulators have already moved in this direction: the EU through the AI Act’s conformity assessments, and the U.S. through audit mandates such as New York City’s Local Law 144 and Colorado’s SB 21-169.

However, this raises a critical question: do these audits deliver meaningful accountability, or are they destined to become procedural box-ticking exercises?

This presentation introduces audience to the layout of the mandatory and voluntary AI assessments and audits under the EU AI Act, NYC LL 144, Colorado SC 21-169, Canadian Directive on Automated Decision Making, NIST, ISO and the OECD principles in terms of their scope and focus. It contrasts these initiatives with established audit regimes in sectors such as finance, highlighting the shortcomings of current AI audit methodologies—most notably the absence of independent third-party auditors, the lack of objective standards, and weak transparency and enforceability.

Note: This presentation is directly based on my research at Oxford University on AI audit methodologies and on my prior work as AI auditor.