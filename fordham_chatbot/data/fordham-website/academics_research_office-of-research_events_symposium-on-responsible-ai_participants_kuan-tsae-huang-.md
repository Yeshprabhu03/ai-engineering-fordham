https://www.fordham.edu/academics/research/office-of-research/events/symposium-on-responsible-ai/participants/kuan-tsae-huang-

# Kuan-Tsae Huang

**Bio:**

Kuan-Tsae Huang, Chair Professor at Asia University and Chairman of the Taiwan Quantum Security Industry Association. His research focuses on Quantum & Responsible AI, Autonomous UV systems and Quantum supercomputing. He held executive positions at IBM, including VP of e-Commerce and helped IBM's business transformation. He was named one of the top 10 Energy Innovators by LAUNCH (Dept. of State) in 2011. He was President of National Taiwan Normal University (NTNU) and CEOs for a startup. He co-authored two books: “Quality Information and Knowledge” and “Building Trustworthy AI Systems”. He has authored over 60 papers/patents and received numerous awards. He received a PhD in EECS from MIT.

**Abstract:**

Recently, TSMC, the world's largest semiconductor fabs, said it had detected “unauthorized activities” that led to the discovery of potential trade secret leaks. As high-tech manufacturing plants become increasingly automated and data-driven, the integration of Sovereign AI—AI systems developed and governed by national or enterprise-level authorities—offers a strategic pathway to secure, resilient, and ethically governed operations. This talk explores how autonomous Uncrewed Vehicles (UVs), including aerial drones, ground rovers, and inspection bots, can be deployed in coordination with sovereign AI architectures for real-time safety monitoring, perimeter security, and predictive maintenance in sensitive industrial environments.

We examine real-world implementations including Japan's AI-enabled chatbot and robotic patrols in semiconductor fabrication facilities, Germany's sovereign AI-driven inspection drones in chemical plants, and the UAE's autonomous surveillance systems in energy infrastructure. The presentation addresses critical engineering challenges including sensor fusion, edge inference, fault tolerance, and explainability requirements for industrial-grade deployments.

Key responsible AI concerns—including bias in threat detection algorithms, explainability in autonomous decision-making processes, and accountability frameworks for incident response—are examined through governance structures and technical safeguards. The talk emphasizes how responsible AI principles of transparency, accountability, and compliance with safety standards can be integrated into sovereign AI architectures while maintaining strategic autonomy.

This presentation advocates for a comprehensive systems-level approach that balances operational autonomy with ethical transparency, enabling high-tech manufacturing plants to operate safely, securely, and responsibly in an era of intelligent automation. Attendees will gain practical insights into designing scalable, secure, and ethically aligned AI-UV systems that meet the demanding requirements of modern industrial automation while preserving strategic control and maintaining public trust in automated industrial systems.