{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ðŸŽ“ **Professor**: Apostolos Filippas\n",
    "\n",
    "### ðŸ“˜ **Class**: AI Engineering\n",
    "\n",
    "### ðŸ“‹ **Homework 4**: Embeddings & Semantic Search\n",
    "\n",
    "### ðŸ“… **Due Date**: Day of Lecture 5, 11:59 PM\n",
    "\n",
    "\n",
    "**Note**: You are not allowed to share the contents of this notebook with anyone outside this class without written permission by the professor.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework, you'll build on Homework 3 (BM25 search) by adding **embedding-based semantic search**.\n",
    "\n",
    "You will:\n",
    "1. **Generate embeddings** using both local (Hugging Face) and API (OpenAI) models\n",
    "2. **Implement cosine similarity** from scratch\n",
    "3. **Implement semantic search** from scratch\n",
    "4. **Compare BM25 vs semantic search** using Recall\n",
    "5. **Compare different embedding models** and analyze their differences\n",
    "\n",
    "**Total Points: 95**\n",
    "\n",
    "---\n",
    "\n",
    "## Instructions\n",
    "\n",
    "- Complete all tasks by filling in code where you see `# YOUR CODE HERE`\n",
    "- You may use ChatGPT, Claude, documentation, Stack Overflow, etc.\n",
    "- When using external resources, briefly cite them in a comment\n",
    "- Run all cells before submitting to ensure they work\n",
    "\n",
    "**Submission:**\n",
    "1. Create a branch called `homework-4`\n",
    "2. Commit and push your work\n",
    "3. Create a PR and merge to main\n",
    "4. Submit the `.ipynb` file on Blackboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 1: Environment Setup (10 points)\n",
    "\n",
    "### 1a. Imports (5 pts)\n",
    "\n",
    "Import the required libraries and load the WANDS data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n"
     ]
    }
   ],
   "source": [
    "# ruff: noqa: E402\n",
    "\n",
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import ONLY data loading from helpers\n",
    "import sys\n",
    "import Stemmer\n",
    "import string\n",
    "sys.path.append('../scripts')\n",
    "from helpers import load_wands_products, load_wands_queries, load_wands_labels\n",
    "\n",
    "# Embedding libraries - we use these directly\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import litellm\n",
    "\n",
    "# Load environment variables for API keys\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "pd.set_option('display.max_colwidth', 80)\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products: 42,994\n",
      "Queries: 480\n",
      "Labels: 233,448\n"
     ]
    }
   ],
   "source": [
    "# Load the WANDS dataset\n",
    "products = load_wands_products()\n",
    "queries = load_wands_queries()\n",
    "labels = load_wands_labels()\n",
    "\n",
    "print(f\"Products: {len(products):,}\")\n",
    "print(f\"Queries: {len(queries):,}\")\n",
    "print(f\"Labels: {len(labels):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Copy BM25 functions from HW3 (5 pts)\n",
    "\n",
    "Copy your BM25 implementation from Homework 3. We'll use it to compare against semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Copy your BM25 functions from Homework 3\n",
    "# Provided functions - run this cell to define them\n",
    "import Stemmer\n",
    "stemmer = Stemmer.Stemmer('english')\n",
    "punct_trans = str.maketrans({key: ' ' for key in string.punctuation})\n",
    "\n",
    "def snowball_tokenize(text: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Tokenize text with Snowball stemming.\n",
    "    \n",
    "    Args:\n",
    "        text: The text to tokenize\n",
    "        \n",
    "    Returns:\n",
    "        List of stemmed tokens\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or text is None:\n",
    "        return []\n",
    "    text = str(text).translate(punct_trans)\n",
    "    tokens = text.lower().split()\n",
    "    return [stemmer.stemWord(token) for token in tokens]\n",
    "\n",
    "def build_index(docs: list[str], tokenizer) -> tuple[dict, list[int]]:\n",
    "    \"\"\"\n",
    "    Build an inverted index from a list of documents.\n",
    "    \n",
    "    Args:\n",
    "        docs: List of document strings to index\n",
    "        tokenizer: Function that takes text and returns list of tokens\n",
    "        \n",
    "    Returns:\n",
    "        index: dict mapping term -> {doc_id: term_count}\n",
    "        doc_lengths: list of document lengths (in tokens)\n",
    "    \"\"\"\n",
    "    index = {}\n",
    "    doc_lengths = []\n",
    "    \n",
    "    for doc_id, doc in enumerate(docs):\n",
    "        tokens = tokenizer(doc)\n",
    "        doc_lengths.append(len(tokens))\n",
    "        term_counts = Counter(tokens)\n",
    "        \n",
    "        for term, count in term_counts.items():\n",
    "            if term not in index:\n",
    "                index[term] = {}\n",
    "            index[term][doc_id] = count\n",
    "    \n",
    "    return index, doc_lengths\n",
    "\n",
    "def get_tf(term: str, doc_id: int, index: dict) -> int:\n",
    "    \"\"\"\n",
    "    Get term frequency for a term in a document.\n",
    "    \n",
    "    Args:\n",
    "        term: The term to look up\n",
    "        doc_id: The document ID\n",
    "        index: The inverted index\n",
    "        \n",
    "    Returns:\n",
    "        Term frequency (count), or 0 if not found\n",
    "    \"\"\"\n",
    "    if term in index and doc_id in index[term]:\n",
    "        return index[term][doc_id]\n",
    "    return 0\n",
    "\n",
    "def get_df(term: str, index: dict) -> int:\n",
    "    \"\"\"\n",
    "    Get document frequency for a term.\n",
    "    \n",
    "    Args:\n",
    "        term: The term to look up\n",
    "        index: The inverted index\n",
    "        \n",
    "    Returns:\n",
    "        Number of documents containing the term\n",
    "    \"\"\"\n",
    "    if term in index:\n",
    "        return len(index[term])\n",
    "    return 0\n",
    "\n",
    "def bm25_idf(df: int, num_docs: int) -> float:\n",
    "    \"\"\"\n",
    "    BM25 IDF formula.\n",
    "    \n",
    "    Args:\n",
    "        df: Document frequency\n",
    "        num_docs: Total number of documents\n",
    "        \n",
    "    Returns:\n",
    "        IDF score\n",
    "    \"\"\"\n",
    "    return np.log((num_docs - df + 0.5) / (df + 0.5) + 1)\n",
    "\n",
    "def bm25_tf(tf: int, doc_len: int, avg_doc_len: float, k1: float = 1.2, b: float = 0.75) -> float:\n",
    "    \"\"\"\n",
    "    BM25 TF normalization.\n",
    "    \n",
    "    Args:\n",
    "        tf: Term frequency\n",
    "        doc_len: Document length in tokens\n",
    "        avg_doc_len: Average document length\n",
    "        k1: Saturation parameter (default 1.2)\n",
    "        b: Length normalization (default 0.75)\n",
    "        \n",
    "    Returns:\n",
    "        Normalized TF score\n",
    "    \"\"\"\n",
    "    return (tf * (k1 + 1)) / (tf + k1 * (1 - b + b * doc_len / avg_doc_len))\n",
    "\n",
    "def score_bm25(query: str, index: dict, num_docs: int, doc_lengths: list[int], \n",
    "               tokenizer, k1: float = 1.2, b: float = 0.75) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Score all documents using BM25.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query\n",
    "        index: Inverted index\n",
    "        num_docs: Total number of documents\n",
    "        doc_lengths: List of document lengths\n",
    "        tokenizer: Tokenization function\n",
    "        \n",
    "    Returns:\n",
    "        Array of scores for each document\n",
    "    \"\"\"\n",
    "    query_tokens = tokenizer(query)\n",
    "    scores = np.zeros(num_docs)\n",
    "    avg_doc_len = np.mean(doc_lengths) if doc_lengths else 1.0\n",
    "    \n",
    "    for token in query_tokens:\n",
    "        df = get_df(token, index)\n",
    "        if df == 0:\n",
    "            continue\n",
    "        \n",
    "        idf = bm25_idf(df, num_docs)\n",
    "        \n",
    "        if token in index:\n",
    "            for doc_id, tf in index[token].items():\n",
    "                tf_norm = bm25_tf(tf, doc_lengths[doc_id], avg_doc_len, k1, b)\n",
    "                scores[doc_id] += idf * tf_norm\n",
    "    \n",
    "    return scores\n",
    "\n",
    "def search_products(query: str, products_df: pd.DataFrame, index: dict, \n",
    "                    doc_lengths: list[int], tokenizer, k: int = 10) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Search products and return top-k results.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query\n",
    "        products_df: DataFrame of products\n",
    "        index: Inverted index\n",
    "        doc_lengths: Document lengths\n",
    "        tokenizer: Tokenization function\n",
    "        k: Number of results to return\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with top-k products and scores\n",
    "    \"\"\"\n",
    "    scores = score_bm25(query, index, len(products_df), doc_lengths, tokenizer)\n",
    "    top_k_idx = np.argsort(-scores)[:k]\n",
    "    \n",
    "    results = products_df.iloc[top_k_idx].copy()\n",
    "    results['score'] = scores[top_k_idx]\n",
    "    results['rank'] = range(1, k + 1)\n",
    "    return results\n",
    "\n",
    "print(\"All functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 2: Understanding Embeddings (15 points)\n",
    "\n",
    "### 2a. Load a local model and generate embeddings (5 pts)\n",
    "\n",
    "Use `sentence-transformers` to load a local embedding model and generate embeddings for a list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52fd876312184194b827155c6d3046fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4497110483d24e748719d0cf77596b38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "568ea90429e848c1a5c5afabd3f99ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bd91ab3a4444f56935d8c9ec0c975b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92cd9632878144348de85592065bb35f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c9ff1eda23433dbba9a5ac2d19ac43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "615a7c6522b74b519fa32d8af6ea0e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e56fed3772c4624a2923a977a66fae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af68a59134894c5abd59edbb7f93129a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdf6b908d5e843c9a5ba2568b5b8ed04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ae250bbef24e6d9ad156eefe53b9a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "271fbcb588464261a3f1e8c83e32e6ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of embeddings: 5\n",
      "Dimension of embeddings: 384\n"
     ]
    }
   ],
   "source": [
    "# Load the all-MiniLM-L6-v2 model using SentenceTransformer\n",
    "\n",
    "model_name = \"all-MiniLM-L6-v2\"  # small + fast local model\n",
    "embed_model = SentenceTransformer(model_name)\n",
    "\n",
    "words = [\"wooden coffee table\", \"oak dining table\", \"red leather sofa\", \"blue area rug\", \"kitchen sink\"]embeddings = embed_model.encode(words, normalize_embeddings=True)\n",
    "\n",
    "print(\"Model:\", model_name)\n",
    "print(\"Embedding shape:\", embeddings.shape)  # (num_words, embedding_dim)\n",
    "\n",
    "# Show a quick preview\n",
    "for w, vec in zip(words, embeddings):\n",
    "    print(w, \"->\", vec[:5], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Implement cosine similarity and create a similarity matrix (5 pts)\n",
    "\n",
    "Implement cosine similarity from scratch:\n",
    "\n",
    "$$\\text{cosine\\_similarity}(a, b) = \\frac{a \\cdot b}{\\|a\\| \\times \\|b\\|}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement cosine similarity from scratch\n",
    "\n",
    "# Create similarity matrix\n",
    "\n",
    "# Display as DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c. Embed using OpenAI API (5 pts)\n",
    "\n",
    "Use `litellm` to get embeddings from OpenAI's API and compare dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use litellm to get an embedding from OpenAI's text-embedding-3-small model\n",
    "# Compare the dimension with the local model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 3: Batch Embedding Products (20 points)\n",
    "\n",
    "### 3a. Embed a product sample (10 pts)\n",
    "\n",
    "Create a combined text field and embed 5,000 products using the local model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a consistent sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined text field (product_name + product_class)\n",
    "# Then embed all products using model.encode()\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Save and load embeddings (5 pts)\n",
    "\n",
    "Save embeddings to a `.npy` file so you don't have to recompute them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings to ../temp/hw4_embeddings.npy\n",
    "# Save products_sample to ../temp/hw4_products.csv\n",
    "# Then load them back and verify they match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c. Cost estimation (5 pts)\n",
    "\n",
    "Estimate the cost to embed all 43K products using OpenAI's API.\n",
    "\n",
    "**Pricing**: text-embedding-3-small costs ~$0.02 per 1 million tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tiktoken to count actual tokens in the sample\n",
    "# Then extrapolate to estimate cost for the full dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 4: Semantic Search (25 points)\n",
    "\n",
    "### 4a. Implement semantic search (15 pts)\n",
    "\n",
    "Implement a semantic search function from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement batch cosine similarity for efficiency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement semantic search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test semantic search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b. Evaluate and compare BM25 vs semantic search (10 pts)\n",
    "\n",
    "Implement Recall@k and compare the two search methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Recall@k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build BM25 index for comparison\n",
    "\n",
    "# Filter queries to those with products in our sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate both BM25 and semantic search on all queries\n",
    "# Calculate Recall@10 for each method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 5: Compare Embedding Models (20 points)\n",
    "\n",
    "### 5a. Embed products with two different models (10 pts)\n",
    "\n",
    "Compare embeddings from:\n",
    "- `BAAI/bge-base-en-v1.5`\n",
    "- `sentence-transformers/all-mpnet-base-v2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the two embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed products with both models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5b. Compare search results between models (10 pts)\n",
    "\n",
    "Evaluate both models on the same queries and analyze differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results for specific queries\n",
    "test_queries = [\"comfortable sofa\", \"star wars rug\", \"modern coffee table\"]\n",
    "# add more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison with a scatter plot\n",
    "# X-axis: BGE Recall@10, Y-axis: MPNet Recall@10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 6: Git Submission (5 points)\n",
    "\n",
    "Submit your work using the Git workflow:\n",
    "\n",
    "- [ ] Create a new branch called `homework-4`\n",
    "- [ ] Commit your work with a meaningful message\n",
    "- [ ] Push to GitHub\n",
    "- [ ] Create a Pull Request\n",
    "- [ ] Merge the PR to main\n",
    "- [ ] Submit the `.ipynb` file on Blackboard\n",
    "\n",
    "The TA will verify your submission by checking the merged PR on GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
